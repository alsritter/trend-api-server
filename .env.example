# API Server 配置
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# MySQL 数据库配置
RELATION_DB_HOST=localhost
RELATION_DB_PORT=3307
RELATION_DB_USER=root
RELATION_DB_PWD=123456
RELATION_DB_NAME=media_crawler_pro

# Redis 配置
REDIS_DB_HOST=localhost
REDIS_DB_PORT=6378
REDIS_DB_PWD=123456
REDIS_DB_NUM=0

# MediaCrawlerPro-Python 路径配置
CRAWLER_BASE_PATH=/app/MediaCrawlerPro-Python
CRAWLER_PYTHON_PATH=python

# 签名服务配置（Docker 环境下为 localhost，因为 SignSrv 与 API Server 在同一容器）
SIGN_SRV_HOST=localhost
SIGN_SRV_PORT=8989

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=/var/log/trend-api-server/app.log

# IP 代理配置（可选）
# 是否启用 IP 代理（True/False）
ENABLE_IP_PROXY=False
# IP 池大小（1-100）
IP_PROXY_POOL_COUNT=2
# IP 提供商名称（kuaidaili）
IP_PROXY_PROVIDER_NAME=kuaidaili
# 快代理配置
KDL_SECERT_ID=your_secret_id
KDL_SIGNATURE=your_signature
KDL_USER_NAME=your_username
KDL_USER_PWD=your_password

# ==========================================
# MediaCrawlerPro-Python 爬虫配置
# 这些配置会通过环境变量传递给 MediaCrawlerPro-Python
# 无需修改 MediaCrawlerPro-Python 项目代码即可使用
# ==========================================

# 基础配置
# 平台：xhs(小红书) | weibo(微博) | douyin(抖音) | kuaishou(快手) | bilibili(B站) | tieba(贴吧) | zhihu(知乎)
CRAWLER_PLATFORM=xhs
# 搜索关键词（逗号分隔）
CRAWLER_KEYWORDS=deepseek,chatgpt
# 爬虫类型：search(关键词搜索) | detail(帖子详情) | creator(创作者主页) | homefeed(首页推荐)
CRAWLER_TYPE=search
# 排序类型（小红书）：popularity_descending(热度降序) | time_descending(时间降序)
CRAWLER_SORT_TYPE=popularity_descending
# 发布时间类型（抖音）：0(不限) | 1(一天内) | 7(一周内) | 182(半年内)
CRAWLER_PUBLISH_TIME_TYPE=0

# 数据保存配置
# 数据保存类型：csv | db | json (建议使用 db)
CRAWLER_SAVE_DATA_OPTION=db
# 账号池保存类型：xlsx | mysql (建议使用 mysql)
CRAWLER_ACCOUNT_POOL_SAVE_TYPE=mysql

# 爬取控制配置
# 开始页数
CRAWLER_START_PAGE=1
# 最大爬取数量
CRAWLER_MAX_NOTES_COUNT=40
# 并发数量（建议设为1，避免被封）
CRAWLER_MAX_CONCURRENCY_NUM=1
# 请求间隔（秒）
CRAWLER_TIME_SLEEP=1

# 评论爬取配置
# 是否爬取评论
CRAWLER_ENABLE_GET_COMMENTS=True
# 是否爬取二级评论
CRAWLER_ENABLE_GET_SUB_COMMENTS=False
# 单帖最大评论数（0表示不限制）
CRAWLER_PER_NOTE_MAX_COMMENTS_COUNT=0

# 断点续爬配置
# 是否启用断点续爬
CRAWLER_ENABLE_CHECKPOINT=True
# 指定检查点ID（留空则使用最新检查点）
CRAWLER_SPECIFIED_CHECKPOINT_ID=
# 检查点存储类型：file | redis
CRAWLER_CHECKPOINT_STORAGE_TYPE=file

# 其他配置
# 是否输出日志到文件
CRAWLER_ENABLE_LOG_FILE=True
# 微博是否爬取全文（可能增加风控概率）
CRAWLER_ENABLE_WEIBO_FULL_TEXT=False
# 缓存类型：redis | memory (建议使用 redis，避免程序重启时代理IP丢失)
CRAWLER_CACHE_TYPE=redis

